{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import section\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler, MinMaxScaler, PowerTransformer, OrdinalEncoder\n",
    "from sklearn.linear_model import Lasso, Ridge, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(\"data/diamonds.csv\", index_col = \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First look at the data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________\n",
      "Number of columns in the dataset: 10\n",
      "Number of rows in the dataset: 53940\n",
      "   carat      cut color clarity  depth  table  price     x     y     z\n",
      "1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
      "2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
      "3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
      "4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
      "5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75\n",
      "______________________________________________________________________________\n",
      "              carat         depth         table         price             x  \\\n",
      "count  53940.000000  53940.000000  53940.000000  53940.000000  53940.000000   \n",
      "mean       0.797940     61.749405     57.457184   3932.799722      5.731157   \n",
      "std        0.474011      1.432621      2.234491   3989.439738      1.121761   \n",
      "min        0.200000     43.000000     43.000000    326.000000      0.000000   \n",
      "25%        0.400000     61.000000     56.000000    950.000000      4.710000   \n",
      "50%        0.700000     61.800000     57.000000   2401.000000      5.700000   \n",
      "75%        1.040000     62.500000     59.000000   5324.250000      6.540000   \n",
      "max        5.010000     79.000000     95.000000  18823.000000     10.740000   \n",
      "\n",
      "                  y             z  \n",
      "count  53940.000000  53940.000000  \n",
      "mean       5.734526      3.538734  \n",
      "std        1.142135      0.705699  \n",
      "min        0.000000      0.000000  \n",
      "25%        4.720000      2.910000  \n",
      "50%        5.710000      3.530000  \n",
      "75%        6.540000      4.040000  \n",
      "max       58.900000     31.800000  \n",
      "______________________________________________________________________________\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 53940 entries, 1 to 53940\n",
      "Data columns (total 10 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   carat    53940 non-null  float64\n",
      " 1   cut      53940 non-null  object \n",
      " 2   color    53940 non-null  object \n",
      " 3   clarity  53940 non-null  object \n",
      " 4   depth    53940 non-null  float64\n",
      " 5   table    53940 non-null  float64\n",
      " 6   price    53940 non-null  int64  \n",
      " 7   x        53940 non-null  float64\n",
      " 8   y        53940 non-null  float64\n",
      " 9   z        53940 non-null  float64\n",
      "dtypes: float64(6), int64(1), object(3)\n",
      "memory usage: 4.5+ MB\n",
      "None\n",
      "______________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"______________________________________________________________________________\")\n",
    "print(\"Number of columns in the dataset:\", len(ds.columns))\n",
    "print(\"Number of rows in the dataset:\", ds.shape[0])\n",
    "print(ds.head())\n",
    "print(\"______________________________________________________________________________\")\n",
    "print(ds.describe())\n",
    "print(\"______________________________________________________________________________\")\n",
    "print(ds.info())\n",
    "print(\"______________________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After first look at the dataset we can conclude that the dataset have no missing values. DS contain 10 columns totally (3 categorical columns, 7 numerical)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the dataset into train and test sets. Test set we are gonna use for final predictions. For validation of our model we'll use cross-validation technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________\n",
      "Number of rows in the train dataset: 37758\n",
      "       carat    cut color clarity  depth  table  price     x     y     z\n",
      "19498   1.21  Ideal     H    VVS2   61.3   57.0   8131  6.92  6.87  4.23\n",
      "31230   0.31  Ideal     E     VS2   62.0   56.0    756  4.38  4.36  2.71\n",
      "22312   1.21  Ideal     E     VS1   62.4   57.0  10351  6.75  6.83  4.24\n",
      "279     0.81  Ideal     F     SI2   62.6   55.0   2795  5.92  5.96  3.72\n",
      "6647    0.79  Ideal     I    VVS2   61.7   56.0   4092  5.94  5.95  3.67\n",
      "______________________________________________________________________________\n",
      "Number of rows in the train dataset: 16182\n",
      "       carat        cut color clarity  depth  table  price     x     y     z\n",
      "1389    0.24      Ideal     G    VVS1   62.1   56.0    559  3.97  4.00  2.47\n",
      "50053   0.58  Very Good     F    VVS2   60.0   57.0   2201  5.44  5.42  3.26\n",
      "41646   0.40      Ideal     E    VVS2   62.1   55.0   1238  4.76  4.74  2.95\n",
      "42378   0.43    Premium     E    VVS2   60.8   57.0   1304  4.92  4.89  2.98\n",
      "17245   1.55      Ideal     E     SI2   62.3   55.0   6901  7.44  7.37  4.61\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(ds, test_size = 0.3, random_state = 42)\n",
    "print(\"______________________________________________________________________________\")\n",
    "print(\"Number of rows in the train dataset:\", train.shape[0])\n",
    "print(train.head())\n",
    "print(\"______________________________________________________________________________\")\n",
    "print(\"Number of rows in the train dataset:\", test.shape[0])\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(path_or_buf='data/train.csv', index=False)\n",
    "test.to_csv(path_or_buf='data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's provide some EDA on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At first let's look on target - \"price\" column:\n",
    "sns.distplot(a=train['price'], kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Price\" column data are not normally distributed. Most of the data distributed at low prices. Maybe transformation distribution to normal will increase performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at Pearson correlation matrix\n",
    "cor_mat = train.corr()\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(cor_mat, annot=True, cmap=plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see a lot of columns are very correlates within each other. So maybe we'll need to drop some of the columns in order to prevent multicollinearity. We'll check this during model construction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get some plots for categorical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain lists of cat and num columns\n",
    "num_features = [col for col in train.columns if train[col].dtype in ['int64', 'float64']] # numeric features\n",
    "cat_features = [col for col in train.columns if train[col].dtype == 'object'] # categorical features\n",
    "num_features.remove('price')\n",
    "\n",
    "print(\"Categorical features:\", cat_features)\n",
    "print(\"Numerical features:\", num_features)\n",
    "\n",
    "# Let's look on categorical features:\n",
    "print(\"Num of cut column unique values:\", train.cut.unique())\n",
    "print(\"Num of color column unique values:\", train.color.unique())\n",
    "print(\"Num of clarity column unique values:\", train.clarity.unique())   \n",
    "\n",
    "# \"cut\" column\n",
    "plt.figure(figsize=(15,6))\n",
    "fig = plt.figure(figsize=(14,4))\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "sns.countplot(x=train.cut).set_title(\"Cut values dictribution\")\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "sns.boxplot(x=train.cut, y=train.price).set_title(\"Cut vs price boxplot\")\n",
    "\n",
    "# \"color\" column\n",
    "plt.figure(figsize=(15,6))\n",
    "fig = plt.figure(figsize=(14,4))\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "sns.countplot(x=train.color).set_title(\"Color values dictribution\")\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "sns.boxplot(x=train.color, y=train.price).set_title(\"Color vs price boxplot\")\n",
    "\n",
    "# \"clarity\" column\n",
    "plt.figure(figsize=(15,6))\n",
    "fig = plt.figure(figsize=(14,4))\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "sns.countplot(x=train.clarity).set_title(\"Clarity values dictribution\")\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "sns.boxplot(x=train.clarity, y=train.price).set_title(\"Clarity vs price boxplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look on numerical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,12))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "# we'll iterate through all numerical columns in train and build regplot (\"price\" dependent) for every column: \n",
    "for i in range(1, len(num_features)+1):\n",
    "    ax = fig.add_subplot(2, 3, i)\n",
    "    sns.regplot(x=train[num_features[i-1]], y=train['price'], ax=ax).set_title(\"Price vs \"+str(num_features[i-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features such as \"x\", \"y\", \"z\" and \"carat\"  have visible impact on price. On the contrary table and depth features seems not to have great impact on price.\n",
    "From regplots several outliers can be detected. As we can see there are several observations with x,y,z values which is impossible. So either these data are missing or some mistakes done in dataset. Since such observations not much we'll drop them from both datasets (train and test). Also we can see couple of outliers with y>30 and z>30. We'll drop these observations as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop outliers\n",
    "train = train.drop(train[train[\"x\"]==0].index)\n",
    "train = train.drop(train[train[\"y\"]==0].index)\n",
    "train = train.drop(train[train[\"z\"]==0].index)\n",
    "train = train.drop(train[train[\"y\"]>30].index)\n",
    "train = train.drop(train[train[\"z\"]>30].index)\n",
    "test = test.drop(test[test[\"x\"]==0].index)\n",
    "test = test.drop(test[test[\"y\"]==0].index)\n",
    "test = test.drop(test[test[\"z\"]==0].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check again on numercial features after removing outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,12))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "# we'll iterate through all numerical columns in train and build regplot (\"price\" dependent) for every column: \n",
    "for i in range(1, len(num_features)+1):\n",
    "    ax = fig.add_subplot(2, 3, i)\n",
    "    sns.regplot(x=train[num_features[i-1]], y=train['price'], ax=ax).set_title(\"Price vs \"+str(num_features[i-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing outliers data look a bit cleaner. Still it can be seen couple of outliers, however we'll leave them as it is, beacause they might be representative for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's look on numerical features dictribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "# we'll iterate through all numerical columns in train and build regplot (\"price\" dependent) for every column: \n",
    "\n",
    "plot_list = [\"x\", \"y\", \"z\", \"carat\"]\n",
    "for i in range(1, len(plot_list)+1):\n",
    "    ax = fig.add_subplot(2, 2, i)\n",
    "    sns.kdeplot(x=train[plot_list[i-1]], ax=ax).set_title(\"KDE plot for \"+str(plot_list[i-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As result of EDA we can conclude:\n",
    "- numerical features such as \"x\", \"y\", \"z\" and \"carat\" have a great impact on diamond price. However these features are also dependent among themselves, so maybe we need to remove some of these features or create new features (something like x+y+z). We'll check this during the further modeling process. Probably, also some scaling for these features needed. We'll also check several options during modeling process.\n",
    "- numerical features such as \"table\" and \"depth\" seems to not have big influence on diamond price. Thus, maybe we should delete them as well.\n",
    "- all three categorical features (\"cut\", \"color\", \"clarity\") can be important for diamond price prediction, however they are unclear. In each group of these features there are available diamonds with big prices as well as diamonds with low prices. So we'll leave these features in dataset. From boxplots for these features it's unclear how we should encode these features. On one side it have to be clear order in them (for example: \"cut\" - quality of the cut (Fair, Good, Very Good, Premium, Ideal)), on the other side its not seen on plots such order. So we will try two options: label encoding and one-hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try two approaches with categorical features encoding: Ordinal Encoding and One-Hot Encoding. Since all categorical features supposed to have some order in their values Ordinal Encoding should provide better results, However, we'll check if this correct for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to choose best preprocessing approaches we'll create a function called bunch_of_models \n",
    "# that creates a bunch of simple models and print their performance on passed dataset. Beside this we'll create validation dataset from train set.\n",
    "\n",
    "# Assign X_train, y_train, X_test, y_test\n",
    "X_train = train.drop(['price'], axis=1)\n",
    "y_train = train[\"price\"]\n",
    "X_test = test.drop(['price'], axis=1)\n",
    "y_test = test[\"price\"]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.3, random_state = 42)\n",
    "\n",
    "def bunch_of_models(X_train, y_train, X_valid, y_valid, model_dict):\n",
    "    for model_name, model in model_dict.items():\n",
    "        if model_name == 'XGB':\n",
    "            model.fit(X_train, y_train, early_stopping_rounds=10, eval_set=[(X_valid, y_valid)])\n",
    "            pred = model.predict(X_valid)\n",
    "            feat_imp = model.feature_importances_\n",
    "            feat_imp_df = pd.DataFrame(data=feat_imp, index=X_train.columns, columns=['Feature_importance'])\n",
    "            plt.figure(figsize=(10,6))\n",
    "            sns.barplot(x=feat_imp_df.index, y=feat_imp_df.Feature_importance).set_title(str(model_name) + \" feature importance:\")\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            pred = model.predict(X_valid)\n",
    "        print(\"___________________________________\")\n",
    "        print(model_name + \" MAE:\", mean_absolute_error(pred, y_valid))\n",
    "        # print(model_name + \" f1_score:\", f1_score(pred, y_test))\n",
    "        # print(model_name + \" confusion matrix:\", confusion_matrix(pred, y_test))\n",
    "        print(\"___________________________________\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal encoding of 'cut', 'color' and 'clarity' features\n",
    "X_train_ord_enc = X_train.copy()\n",
    "X_valid_ord_enc = X_valid.copy()\n",
    "X_test_ord_enc = X_test.copy()\n",
    "X_train_ord_enc['cut'] = X_train_ord_enc['cut'].map({'Fair':1, 'Good':2, 'Very Good':3, 'Premium':4, 'Ideal':5}).astype(int)\n",
    "X_train_ord_enc['color'] = X_train_ord_enc['color'].map({'J':1, 'I':2, 'H':3, 'G':4, 'F':5, 'E':6, 'D':7}).astype(int)\n",
    "X_train_ord_enc['clarity'] = X_train_ord_enc['clarity'].map({'I1':1, 'SI2':2, 'SI1':3, 'VS2':4, 'VS1':5, 'VVS2':6, 'VVS1':7, 'IF':8}).astype(int)\n",
    "X_valid_ord_enc['cut'] = X_valid_ord_enc['cut'].map({'Fair':1, 'Good':2, 'Very Good':3, 'Premium':4, 'Ideal':5}).astype(int)\n",
    "X_valid_ord_enc['color'] = X_valid_ord_enc['color'].map({'J':1, 'I':2, 'H':3, 'G':4, 'F':5, 'E':6, 'D':7}).astype(int)\n",
    "X_valid_ord_enc['clarity'] = X_valid_ord_enc['clarity'].map({'I1':1, 'SI2':2, 'SI1':3, 'VS2':4, 'VS1':5, 'VVS2':6, 'VVS1':7, 'IF':8}).astype(int)\n",
    "X_test_ord_enc['cut'] = X_test_ord_enc['cut'].map({'Fair':1, 'Good':2, 'Very Good':3, 'Premium':4, 'Ideal':5}).astype(int)\n",
    "X_test_ord_enc['color'] = X_test_ord_enc['color'].map({'J':1, 'I':2, 'H':3, 'G':4, 'F':5, 'E':6, 'D':7}).astype(int)\n",
    "X_test_ord_enc['clarity'] = X_test_ord_enc['clarity'].map({'I1':1, 'SI2':2, 'SI1':3, 'VS2':4, 'VS1':5, 'VVS2':6, 'VVS1':7, 'IF':8}).astype(int)\n",
    "\n",
    "print(\"After Ordinal Encoding:\\n\", X_train_ord_enc.loc[:, ['cut', 'color', 'clarity']])\n",
    "print(\"After Ordinal Encoding:\\n\", X_valid_ord_enc.loc[:, ['cut', 'color', 'clarity']])\n",
    "print(\"After Ordinal Encoding:\\n\", X_test_ord_enc.loc[:, ['cut', 'color', 'clarity']])\n",
    "\n",
    "# One-Hot Encoding of 'cut', 'color' and 'clarity' features\n",
    "X_train_one_hot = X_train.copy()\n",
    "X_valid_one_hot = X_valid.copy()\n",
    "\n",
    "X_train_one_hot = pd.get_dummies(X_train_one_hot)\n",
    "X_valid_one_hot = pd.get_dummies(X_valid_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's check what method performs better during modeling. \n",
    "# We'll pass to bunch_of_models func several simple regressor models.\n",
    "\n",
    "model_dict = dict([\n",
    "    ('Lasso', Lasso()),\n",
    "    ('Ridge', Ridge()),\n",
    "    ('SGD', SGDRegressor()),\n",
    "    ('SVM', SVR()),\n",
    "    ('AdaBoost', AdaBoostRegressor()),\n",
    "    ('RF', RandomForestRegressor()),\n",
    "    ('XGB', XGBRegressor())\n",
    "])\n",
    "\n",
    "print(\"Ordinal encoding performance:\\n\")\n",
    "bunch_of_models(X_train_ord_enc, y_train, X_valid_ord_enc, y_valid, model_dict)\n",
    "print(\"One-Hot Encoding performance:\\n\")\n",
    "bunch_of_models(X_train_one_hot, y_train, X_valid_one_hot, y_valid, model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see RandomForest model preforms much better then any other. Compared two encoding approaches One-Hot Encoding works better for linear models, however for other (especially for RF model) ordinal encoding works better. SGD model show something weird, probably data need to be additionally preprocessed for this model or model have to be tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check feature importances in ordinal encoded dataset using RandomForrest and XGBoost models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train_ord_enc, y_train)\n",
    "rf_pred = rf_model.predict(X_valid_ord_enc)\n",
    "print(\"RF MAE:\", mean_absolute_error(rf_pred, y_valid))\n",
    "\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_model.fit(X_train_ord_enc, y_train, early_stopping_rounds=10, eval_set=[(X_valid_ord_enc, y_valid)])\n",
    "xgb_pred = rf_model.predict(X_valid_ord_enc)\n",
    "print(\"XGB MAE:\", mean_absolute_error(xgb_pred, y_valid))\n",
    "\n",
    "rf_feat_imp = pd.DataFrame(data=rf_model.feature_importances_, index=X_train_ord_enc.columns, columns=['Feature_importance'])\n",
    "xgb_feat_imp = pd.DataFrame(data=xgb_model.feature_importances_, index=X_train_ord_enc.columns, columns=['Feature_importance'])\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "sns.barplot(x=rf_feat_imp.index, y=rf_feat_imp.Feature_importance).set_title(\"Random Forest feature importance:\")\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "sns.barplot(x=xgb_feat_imp.index, y=xgb_feat_imp.Feature_importance).set_title(\"XGBoost feature importance:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that 'depth' and 'table' columns doesn't have any impact on both RF and XGB models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to drop a couple of columns and check whether it change performance sufficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 'depth' and 'table' columns\n",
    "X_train_ord_enc_red = X_train_ord_enc.drop(['depth', 'table'], axis=1)\n",
    "X_valid_ord_enc_red = X_valid_ord_enc.drop(['depth', 'table'], axis=1)\n",
    "\n",
    "X_train_one_hot_red = X_train_one_hot.drop(['depth', 'table'], axis=1)\n",
    "X_valid_one_hot_red = X_valid_one_hot.drop(['depth', 'table'], axis=1)\n",
    "\n",
    "# and check again performance\n",
    "print(\"Ordinal encoding performance:\\n\")\n",
    "bunch_of_models(X_train_ord_enc_red, y_train, X_valid_ord_enc_red, y_valid, model_dict)\n",
    "print(\"One-Hot Encoding performance:\\n\")\n",
    "bunch_of_models(X_train_one_hot_red, y_train, X_valid_one_hot_red, y_valid, model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most of the models performance is pretty much the same after droping 'depth' and 'table' columns. So for further modeling we are not gonna use these columns in order to reduce datasets size. Surprisingly, SGD model performed much better after dropping operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to create several new features. We are gonna use ordinal encoded dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 'depth' and 'table' columns\n",
    "X_train_ord_enc.drop(['depth', 'table'], axis=1, inplace=True)\n",
    "X_valid_ord_enc.drop(['depth', 'table'], axis=1, inplace=True)\n",
    "\n",
    "X_train_new = X_train_ord_enc.copy()\n",
    "X_valid_new = X_valid_ord_enc.copy()\n",
    "\n",
    "# create sum of x, y, z and their squares\n",
    "X_train_new[\"xyz_sum\"] = X_train_new['x'] + X_train_new['y'] + X_train_new['z']  # sum of x, y, z\n",
    "X_train_new['x^2'] = X_train_new['x'] * X_train_new['x'] # square x\n",
    "X_train_new['y^2'] = X_train_new['y'] * X_train_new['y'] # square y\n",
    "X_train_new['z^2'] = X_train_new['z'] * X_train_new['z'] # square z\n",
    "X_train_new['carat'] = X_train_new['carat'] * X_train_new['carat'] # square carat value\n",
    "\n",
    "X_valid_new[\"xyz_sum\"] = X_valid_new['x'] + X_valid_new['y'] + X_valid_new['z']\n",
    "X_valid_new['x^2'] = X_valid_new['x'] * X_valid_new['x']\n",
    "X_valid_new['y^2'] = X_valid_new['y'] * X_valid_new['y']\n",
    "X_valid_new['z^2'] = X_valid_new['z'] * X_valid_new['z']\n",
    "X_valid_new['carat'] = X_valid_new['carat'] * X_valid_new['carat']\n",
    "\n",
    "# and check again performance\n",
    "print(\"Ordinal encoding performance:\\n\")\n",
    "bunch_of_models(X_train_new, y_train, X_valid_new, y_valid, model_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding other features does not improve performance of any model. So we'll not add these features into our datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's construct Pipeline inside GridSearch in oreder to find the best scaling and encoding approaches for dataset and tune model. We are gonna create two separate GridSearch Pipelines with RandomForest model and with XGBoost model accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At first let's define pipeline_constructor function that constructs preprocessor for handling our data before modeling\n",
    "def grid_search_pipeline(X_train, y_train, model=XGBRegressor(), param_grid=None):\n",
    "    \"\"\"\n",
    "    Construct Pipelines for numerical and categorical columns.\n",
    "    Create self.preprocessor and self.preprocessor_dict for final Pipeline and further GridSearch\n",
    "    \"\"\"\n",
    "\n",
    "    # At first we'll find columns with numerical and categorical values\n",
    "    num_features = [col for col in X_train.columns if X_train[col].dtype in ['int64', 'float64']]\n",
    "    cat_features = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "\n",
    "    # Pipeline for numerical features that contains scaling and normalization operations\n",
    "    num_transformer = Pipeline(steps=[\n",
    "        ('scaler', 'passthrough'),\n",
    "        ('norm', 'passthrough')\n",
    "    ])\n",
    "\n",
    "    # Pipeline for categorical features that contains encoding operation\n",
    "    cat_transformer = Pipeline(steps=[\n",
    "        ('encode', 'passthrough')\n",
    "    ])\n",
    "\n",
    "    # Combining of num and cat Pipelines into one preprocessor step using ColumnTransformer.\n",
    "    # This preprocessor will be used in final Pipeline and further in GridSearch\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features)\n",
    "    ])\n",
    "    \n",
    "    # Constructing of final Pipeline taht contains preprocessor and regression model\n",
    "    final_estimator = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "    \n",
    "    # Finally GridSearch construction. As estimator parameter of GridSearch we'll pass our final Pipeline:\n",
    "    # If model is XGBoost then we additionally split dataset to train and validation in order to have possibility of early_stopping using\n",
    "    if model == XGBRegressor():\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.3, random_state = 42)\n",
    "        grid_search = GridSearchCV(regressor, param_grid=param_grid, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train, early_stopping_rounds=20, eval_set=[(X_valid, y_valid)])\n",
    "    else:\n",
    "        grid_search = GridSearchCV(final_estimator, param_grid=param_grid, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "    return grid_search.best_score_, grid_search.best_estimator_, grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's again reassign X_train, y_train, X_test, y_test. Now X_train doesn't have any preprocessing except outliers removing and removing of 'depth' and 'table' columns.\n",
    "X_train = train.drop(['price', 'depth', 'table'], axis=1)\n",
    "y_train = train[\"price\"]\n",
    "X_test = test.drop(['price','depth', 'table'], axis=1)\n",
    "y_test = test[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now we are gonna pass into GridSearch two models: RF and XGB.\n",
    "# We'll create two parameter dictionaries for every model. We try to checck different scaling and encoding approaches, as well as different hyperparameters values for regressors.\n",
    "\n",
    "# categories for OrdinalEncoder\n",
    "cut_categories = ['Fair', 'Good', 'Very Good', 'Premium', 'Ideal']\n",
    "color_categories = ['J', 'I', 'H', 'G', 'F', 'E', 'D']\n",
    "clarity_categories = ['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF']\n",
    "\n",
    "# dict with preprocessing parameters\n",
    "preprocessor_dict = dict(preprocessor__num__scaler=[StandardScaler(), RobustScaler(), MinMaxScaler()],\n",
    "                         preprocessor__num__norm=[PowerTransformer()],\n",
    "                         preprocessor__cat__encode=[OrdinalEncoder(categories=[cut_categories, color_categories, clarity_categories]), OneHotEncoder()]\n",
    "                        )\n",
    "\n",
    "# dict with RandomForest model hyperparameters\n",
    "RFC_dict = dict(regressor__n_estimators=[100, 500, 900],\n",
    "                regressor__min_samples_leaf=[1, 2, 4])\n",
    "RFC_dict.update(preprocessor_dict)\n",
    "\n",
    "# dict with XGBoost model hyperparameters\n",
    "XGB_dict = dict(regressor__n_estimators=[100, 500],\n",
    "                regressor__max_depth=[1, 2])\n",
    "XGB_dict.update(preprocessor_dict)\n",
    "\n",
    "# Finally let's find best estimators based on RF and XGB\n",
    "RF_bs, RF_be, RF_bp =  grid_search_pipeline(X_train, y_train, model=RandomForestRegressor(), param_grid=preprocessor_dict)\n",
    "#XGB_bs, XGB_be, XGB_bp = grid_search_pipeline(X_train, y_train, model=XGBRegressor(), param_grid=XGB_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's display the results of GridSearch estimation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(-RF_bs)\n",
    "print(RF_bp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make predictions of test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = RF_be.predict(X_test)\n",
    "print(\" MAE:\", mean_absolute_error(pred, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
